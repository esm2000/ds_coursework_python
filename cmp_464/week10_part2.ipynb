{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Load Data using Web API\n",
    "\n",
    "Many websites (Twitter, Facebook, Kaggle, Reddit, ...) offer Application Programming Interfaces (APIs) which provide access to data on their web server. Today we will use Twitter API to download and analyze some tweets.\n",
    "\n",
    "**Get started with Twitter API:**\n",
    "\n",
    "1. Sign up on Twitter.\n",
    "2. Apply for [develop access](https://developer.twitter.com/en/apps).\n",
    "3. Create a Twitter app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tweepy\n",
      "  Downloading https://files.pythonhosted.org/packages/36/1b/2bd38043d22ade352fc3d3902cf30ce0e2f4bf285be3b304a2782a767aec/tweepy-3.8.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: requests>=2.11.1 in c:\\anaconda3\\lib\\site-packages (from tweepy) (2.22.0)\n",
      "Requirement already satisfied: PySocks>=1.5.7 in c:\\anaconda3\\lib\\site-packages (from tweepy) (1.7.0)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading https://files.pythonhosted.org/packages/c2/e2/9fd03d55ffb70fe51f587f20bcf407a6927eb121de86928b34d162f0b1ac/requests_oauthlib-1.2.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\anaconda3\\lib\\site-packages (from tweepy) (1.12.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\anaconda3\\lib\\site-packages (from requests>=2.11.1->tweepy) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda3\\lib\\site-packages (from requests>=2.11.1->tweepy) (2019.6.16)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\anaconda3\\lib\\site-packages (from requests>=2.11.1->tweepy) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\anaconda3\\lib\\site-packages (from requests>=2.11.1->tweepy) (1.24.2)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading https://files.pythonhosted.org/packages/05/57/ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704/oauthlib-3.1.0-py2.py3-none-any.whl (147kB)\n",
      "Installing collected packages: oauthlib, requests-oauthlib, tweepy\n",
      "Successfully installed oauthlib-3.1.0 requests-oauthlib-1.2.0 tweepy-3.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.3; however, version 19.3.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# Install tweepy package for Python\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy and paste tokens from \"Keys and Access Tokens\" tab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consumer_key = \"(put your token here)\"\n",
    "# consumer_secret = \"(put your token here)\"\n",
    "# access_token = \"(put your token here)\"\n",
    "# access_token_secret = \"(put your token here)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create API object to access twitter data\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Retrieve tweets from timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My timeline\n",
    "public_tweets = api.home_timeline(tweet_mode = \"extended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look into one tweet data\n",
    "tweet = public_tweets[1]\n",
    "tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the _json attribute contains info of the tweet\n",
    "tweet._json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find specific info\n",
    "print(tweet.full_text)\n",
    "print(tweet.author.name)\n",
    "print(tweet.created_at)\n",
    "print(tweet.author.location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Retrieve Tweets from Another User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"nytimes\"\n",
    "tweetCount = 20\n",
    "results = api.user_timeline(id=name, count=tweetCount, tweet_mode = \"extended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in results:\n",
    "    print('-' * 80)\n",
    "    print(tweet.full_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Search for Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_words = \"wildfires -filter:retweets\"\n",
    "date_since = \"2019-10-01\"\n",
    "cursor = tweepy.Cursor(api.search,\n",
    "                       q=search_words,\n",
    "                       lang=\"en\",\n",
    "                       since=date_since,\n",
    "                       tweet_mode = \"extended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = cursor.items(10)\n",
    "for tweet in tweets:\n",
    "    print('-' * 80)\n",
    "    print(tweet.full_text)\n",
    "    print(tweet.author.name)\n",
    "    print(tweet.author.location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pandas DataFrame to store tweets, authors, and locations\n",
    "import pandas as pd\n",
    "\n",
    "# Create an empty data frame\n",
    "tweets_df = pd.DataFrame(columns=['Name', 'Location', 'Text'])\n",
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append tweets data to the data frame\n",
    "tweets = cursor.items(10)\n",
    "count = 0\n",
    "for tweet in tweets:\n",
    "    tweets_df.loc[count, :] = [tweet.author.name,\n",
    "                               tweet.author.location,\n",
    "                               tweet.full_text]\n",
    "    count += 1\n",
    "                               \n",
    "tweets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Binary File Formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. pickle\n",
    "The `pickle` module implements binary protocols for serializing and de-serializing a Python object structure. Only Python can properly read and write pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a data frame first\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "values = np.array([\n",
    "    [100, 80, 95, 'A'],\n",
    "    [55, 60, 45, 'F'],\n",
    "    [70, 75, 90, 'A'],\n",
    "    [75, 70, 60, 'D'],\n",
    "    [60, 73, 75, 'C'],\n",
    "    [72, 63, -1, 'NA']\n",
    "])\n",
    "df = pd.DataFrame(values,\n",
    "                   columns=['Midterm', 'Project', 'Final', 'LetterGrade'],\n",
    "                   index=['Alex', 'Bob', 'Chris', 'Doug', 'Eva', \"Frank\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as a .pickle file\n",
    "df.to_pickle(\"Data/temp/data.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pickle file\n",
    "df_pickle = pd.read_pickle(\"Data/temp/data.pickle\")\n",
    "df_pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. HDF5\n",
    "The \"HDF\" stands for \"hierarchical data format\". HDF5 can be a good choice for working with very large datasets that don't fit into memory, as you can efficiently read and write small sections of large arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Col1': np.random.randn(100),\n",
    "    'Col2': np.random.randn(100)\n",
    "})\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_hdf('Data/temp/data.h5', 'obj1', format='table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hdf5 = pd.read_hdf('Data/temp/data.h5', 'obj1', where=['index < 3'])\n",
    "df_hdf5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. feather\n",
    "The feather format is adapted from the R statistical language. It has extremely high read and write performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "df.to_feather('Data/temp/data.feather')\n",
    "end = time.time()\n",
    "print(\"Time cost:\", (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "df_feather = pd.read_feather('Data/temp/data.feather')\n",
    "end = time.time()\n",
    "print(\"Time cost:\", (end - start))\n",
    "df_feather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Interacting with Databases\n",
    "In a business setting, most data may not be stored in text or binary files. SQL-based relational databases (such as mySQL) are in wide use.\n",
    "\n",
    "Python has sqlite3 package to interact with databases, and Pandas has some functions to simplify the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SQLite database\n",
    "import sqlite3\n",
    "query = \"\"\"\n",
    "CREATE TABLE test\n",
    "(a VARCHAR(20), b VARCHAR(20),\n",
    " c REAL,        d INTEGER\n",
    ");\"\"\"\n",
    "con = sqlite3.connect('Data/temp/data.sqlite')\n",
    "con.execute(query)\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"\"\"\n",
    "# DROP TABLE test\n",
    "# \"\"\"\n",
    "# con.execute(query)\n",
    "# con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert a few rows of data\n",
    "data = [('Atlanta', 'Georgia', 1.25, 6),\n",
    "        ('Tallahassee', 'Florida', 2.6, 3),\n",
    "        ('Sacramento', 'California', 1.7, 5)]\n",
    "stmt = \"INSERT INTO test VALUES(?, ?, ?, ?)\"\n",
    "con.executemany(stmt, data)\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select data\n",
    "cursor = con.execute('select * from test')\n",
    "rows = cursor.fetchall()\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve columns names\n",
    "cursor.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pandas data frame\n",
    "columns = [x[0] for x in cursor.description]\n",
    "df = pd.DataFrame(rows, columns=columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use package `sqlalchemy` to create a data frame directly from a database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as sqla\n",
    "db = sqla.create_engine('sqlite:///Data/temp/data.sqlite')\n",
    "df = pd.read_sql('select * from test', db)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
